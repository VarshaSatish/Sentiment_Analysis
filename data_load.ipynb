{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_load.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"G_UheypxqoqR"},"source":["---\n","This notebook contains the code to create .dat format files from the glove dataset. For every vector length dataset, 2 pickled files are created, one containing words while other containing their indices. In the \"word_embedding_test\", we then create a dictionary from these files and test them.\n","The code reference for the same was taken from https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76.\n","\n","---"]},{"cell_type":"code","metadata":{"id":"ASd6WvR4u90n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5541ee1-04e9-4994-90d8-84b78d4d12bd"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QFvCP1OWzPyL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28eaac78-b49a-41b2-ee9f-6cf953be5aa6"},"source":["!pip install bcolz --quiet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bcolz\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.5)\n","Building wheels for collected packages: bcolz\n","  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2668988 sha256=232a2d44a604db879078857368d149a93bfe8464b41d3d02703f5814c3f18f43\n","  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n","Successfully built bcolz\n","Installing collected packages: bcolz\n","Successfully installed bcolz-1.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UGDDV-KxiHJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"31732cad-9df1-447c-fd4f-e96061dee0af"},"source":["# # No need to run again\n","\n","# !unzip './drive/My Drive/AML_assignments/Assignment2/glove.6B.zip' -d './drive/My Drive/AML_2'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  ./drive/My Drive/AML_assignments/Assignment2/glove.6B.zip\n","  inflating: ./drive/My Drive/AML_2/glove.6B.50d.txt  \n","  inflating: ./drive/My Drive/AML_2/glove.6B.100d.txt  \n","  inflating: ./drive/My Drive/AML_2/glove.6B.200d.txt  \n","  inflating: ./drive/My Drive/AML_2/glove.6B.300d.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DbpkNysyyKvN"},"source":["import bcolz\n","import numpy as np\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FArzmuAWecsl"},"source":["\n","---\n","> Libraries/ Packages imported\n","---\n","\n","> *   The package bcolz provides columnar, chunked data containers that can be compressed either in-memory or on-disk. Column storage allows for efficiently querying tables, as well as for cheap column addition and removal. It is based on NumPy.\n","*   carray: Container for homogeneous & heterogeneous (row-wise) data.\n","*   carray is very similar to a NumPy ndarray in that it supports the same types and basic data access interface. The main difference between the two is that a carray can keep data compressed (both in-memory and on-disk), allowing to deal with larger datasets with the same amount of memory/disk.\n","*The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream. \n","* The function pickle.dump() writes the pickled representation of the object obj to the open file object file.\n","\n","\n","\n","---"]},{"cell_type":"code","metadata":{"id":"Uewp2nS_45G3"},"source":["words = []\n","idx = 0\n","word2idx = {}\n","vectors = bcolz.carray(np.zeros(1), rootdir=f'./drive/My Drive/AML_2/6B.50d.dat', mode='w')\n","\n","# Picking words line wise and arranging them in 'vectors'\n","\n","with open(f'./drive/My Drive/AML_2/glove.6B.50d.txt', 'rb') as f:\n","    for l in f:\n","        line = l.decode().split()\n","        word = line[0]\n","        words.append(word)\n","        word2idx[word] = idx\n","        idx += 1\n","        vect = np.array(line[1:]).astype(np.float)\n","        vectors.append(vect)\n","\n","# Flushing all the rows in 'vector' to carray    \n","vectors = bcolz.carray(vectors[1:].reshape((400000, 50)), rootdir=f'./drive/My Drive/AML_2/6B.50d.dat', mode='w')\n","vectors.flush()\n","# Storing the vectors and their indices to pkl files\n","pickle.dump(words, open(f'./drive/My Drive/AML_2/6B.50_words.pkl', 'wb'))\n","pickle.dump(word2idx, open(f'./drive/My Drive/AML_2/6B.50_idx.pkl', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zebEMdwZX4Vg"},"source":["words = []\n","idx = 0\n","word2idx = {}\n","vectors = bcolz.carray(np.zeros(1), rootdir=f'./drive/My Drive/AML_2/6B.200d.dat', mode='w')\n","\n","# Picking words line wise and arranging them in 'vectors'\n","\n","with open(f'./drive/My Drive/AML_2/glove.6B.200d.txt', 'rb') as f:\n","    for l in f:\n","        line = l.decode().split()\n","        word = line[0]\n","        words.append(word)\n","        word2idx[word] = idx\n","        idx += 1\n","        vect = np.array(line[1:]).astype(np.float)\n","        vectors.append(vect)\n","\n","# Flushing all the rows in 'vector' to carray    \n","vectors = bcolz.carray(vectors[1:].reshape((400000, 200)), rootdir=f'./drive/My Drive/AML_2/6B.200d.dat', mode='w')\n","vectors.flush()\n","# Storing the vectors and their indices to pkl files\n","pickle.dump(words, open(f'./drive/My Drive/AML_2/6B.200_words.pkl', 'wb'))\n","pickle.dump(word2idx, open(f'./drive/My Drive/AML_2/6B.200_idx.pkl', 'wb'))"],"execution_count":null,"outputs":[]}]}